{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Notebook for running the project pipeline and experiments separately"
      ],
      "metadata": {
        "id": "1PfbkUah6dlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "0gu0M923WPYE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys, os\n",
        "\n",
        "# Path to the folder where utils.py is located\n",
        "GOOGLE_DRIVE_PATH = '/content/drive/MyDrive/CS7643 Project/OMSCS_7643_F2025_Project/'\n",
        "\n",
        "# Add to Python's import search path\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n",
        "\n",
        "# Check that utils.py is visible\n",
        "print(\"Files in path:\", os.listdir(GOOGLE_DRIVE_PATH))\n",
        "\n",
        "# Now import the helper functions\n"
      ],
      "metadata": {
        "id": "EalDQhsuWPYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3nRIW7gwSvGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "%cd $GOOGLE_DRIVE_PATH\n"
      ],
      "metadata": {
        "id": "cG_2zPe8WPYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# from scripts.Trans import train_transformer, predict, train_classifier\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "H56ZO-PeWPYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "-aqlMZceWPYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# os.chdir(Path().resolve().parent)\n",
        "print(\"Current working directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "YIhVQn_NPBlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PFWmdTqb5cJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python scripts/preprocess.py"
      ],
      "metadata": {
        "id": "DUQMn_DbPBle",
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python scripts/embedding.py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VciU0XQjPBlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/build_features.py --lookback 24"
      ],
      "metadata": {
        "id": "GP_sxK1wJWhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Test Build features\n",
        "# import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from pathlib import Path\n",
        "\n",
        "# import importlib.util\n",
        "\n",
        "# spec = importlib.util.spec_from_file_location(\n",
        "#     \"build_features\", \"scripts/build_features.py\"\n",
        "# )\n",
        "# build_features = importlib.util.module_from_spec(spec)\n",
        "# spec.loader.exec_module(build_features)\n",
        "\n",
        "# # ===== Test Settings =====\n",
        "# FEATURE_DIR = Path(\"output/features\")\n",
        "# LOOKBACK = 24\n",
        "# MODES = [\"mean\", \"volume\", \"exp_decay\", \"max\", \"attn\"]\n",
        "\n",
        "\n",
        "# def run_one_test(mode):\n",
        "#     print(f\"\\n\\n==============================\")\n",
        "#     print(f\"TEST: lookback_mode = {mode}\")\n",
        "#     print(f\"==============================\")\n",
        "\n",
        "#     # delete old files\n",
        "#     for f in [\"X.npy\", \"y.npy\", \"dataset.parquet\"]:\n",
        "#         fp = FEATURE_DIR / f\n",
        "#         if fp.exists():\n",
        "#             fp.unlink()\n",
        "\n",
        "#     # set args\n",
        "#     import sys\n",
        "#     sys.argv = [\n",
        "#         \"build_features.py\",\n",
        "#         \"--lookback\", str(LOOKBACK),\n",
        "#         \"--lookback-mode\", mode,\n",
        "#     ]\n",
        "\n",
        "#     # 运行 main()\n",
        "#     try:\n",
        "#         build_features.main()\n",
        "#     except Exception as e:\n",
        "#         print(\"Script crashed:\", e)\n",
        "#         return False\n",
        "\n",
        "#     # check files\n",
        "#     x_file = FEATURE_DIR / \"X.npy\"\n",
        "#     y_file = FEATURE_DIR / \"y.npy\"\n",
        "#     df_file = FEATURE_DIR / \"dataset.parquet\"\n",
        "\n",
        "#     if not x_file.exists():\n",
        "#         print(\"Missing X.npy\")\n",
        "#         return False\n",
        "#     if not y_file.exists():\n",
        "#         print(\"Missing y.npy\")\n",
        "#         return False\n",
        "#     if not df_file.exists():\n",
        "#         print(\"Missing dataset.parquet\")\n",
        "#         return False\n",
        "\n",
        "#     # load data\n",
        "#     X = np.load(x_file)\n",
        "#     Y = np.load(y_file)\n",
        "#     df = pd.read_parquet(df_file)\n",
        "\n",
        "#     print(\"Shapes:\", X.shape, Y.shape)\n",
        "\n",
        "#     if len(X) == 0 or len(Y) == 0:\n",
        "#         print(\"Empty X or y!\")\n",
        "#         return False\n",
        "\n",
        "#     if X.shape[0] != Y.shape[0]:\n",
        "#         print(\"X and y length mismatch!\")\n",
        "#         return False\n",
        "\n",
        "#     if X.ndim != 2:\n",
        "#         print(\"X must be 2D\")\n",
        "#         return False\n",
        "\n",
        "#     if Y.ndim != 1:\n",
        "#         print(\"y must be 1D\")\n",
        "#         return False\n",
        "\n",
        "#     if df.shape[0] != X.shape[0]:\n",
        "#         print(\"dataset.parquet row mismatch!\")\n",
        "#         return False\n",
        "\n",
        "#     print(\"Files validated OK\")\n",
        "#     return True\n",
        "\n",
        "\n",
        "\n",
        "# # ===== Run all tests =====\n",
        "# print(\"\\n=== Running Jupyter Test Suite for build_features.py ===\")\n",
        "\n",
        "# passed = 0\n",
        "\n",
        "# for m in MODES:\n",
        "#     ok = run_one_test(m)\n",
        "#     if ok:\n",
        "#         print(f\"PASS: {m}\")\n",
        "#         passed += 1\n",
        "#     else:\n",
        "#         print(f\"FAIL: {m}\")\n",
        "\n",
        "# print(\"\\n==============================\")\n",
        "# print(f\"Final Summary: {passed}/{len(MODES)} tests passed\")\n",
        "# print(\"==============================\")\n"
      ],
      "metadata": {
        "id": "I41xXfJ1ZBai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python scripts/train.py --model lr --seq_len 1 --epochs 30"
      ],
      "metadata": {
        "id": "Qw8r_wS9PBlg",
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/predict.py --model lr --seq_len 1"
      ],
      "metadata": {
        "id": "vj7Mje0jttbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python scripts//train.py --model transformer --seq_len 12 \\\n",
        "    --model transformer \\\n",
        "    --batch_size 64 \\\n",
        "    --lr 5e-5 \\\n",
        "    --epochs 50 \\\n",
        "    --weight_decay 1e-4 \\\n",
        "    --grad_clip 1.0 \\\n",
        "    --scheduler cosine_warmup \\\n",
        "    --warmup_pct 0.1 \\\n",
        "    --ema_decay 0.995 \\\n",
        "    --seed 42"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ap7KnZQOPBlh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python scripts/predict.py --model transformer --seq_len 12"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TdPq9SM3PBli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/train.py --model gru --num_layers 3\n",
        "\n"
      ],
      "metadata": {
        "id": "3jeOvP_PrDJp",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/evaluate.py --predictions output/predictions/predictions_transformer.csv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rCJaytltZ2ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Check Data used for trainning\n",
        "df = pd.read_parquet(\"output/features/dataset.parquet\")\n",
        "df.tail()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oXJIZHgdbGqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Board Based First Round Tuning (Sub rounds 1-2 are experimental trails, and 3-5 are used as base for the second round)"
      ],
      "metadata": {
        "id": "52YcNoHoo4By"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Sub)First Round Tuning - 24 hours lookback without changing feature aggregation"
      ],
      "metadata": {
        "id": "xzJ9RsdFiOTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.hypersearch import HyperSearch\n",
        "\n",
        "hs = HyperSearch(\n",
        "    max_runs=2000,\n",
        "    search_mode=\"full\"   # or \"quick\"\n",
        ")\n",
        "hs.run()"
      ],
      "metadata": {
        "id": "S8KM70TkbGf1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Round Tuning Best Model"
      ],
      "metadata": {
        "id": "Eg0Dzs6UiKgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "## The original file location has been moved to output1128 folder\n",
        "best_dir = \"/content/drive/MyDrive/CS7643 Project/OMSCS_7643_F2025_Project/output/hyper_runs/run_0103\"\n",
        "\n",
        "with open(best_dir + \"/config.json\") as f:\n",
        "    config = json.load(f)\n",
        "config\n"
      ],
      "metadata": {
        "id": "-EnYMuRBbGby",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/train.py \\\n",
        " --model gru \\\n",
        " --seq_len 8 \\\n",
        " --batch_size 64 \\\n",
        " --lr 0.0003 \\\n",
        " --epochs 30 \\\n",
        " --weight_decay 0.0 \\\n",
        " --warmup_pct 0.1 \\\n",
        " --ema_decay 0.995 \\\n",
        " --hidden_dim 512\n"
      ],
      "metadata": {
        "id": "Jkk7OP21bGRF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/predict.py \\\n",
        " --model gru \\\n",
        " --seq_len 8 \\\n",
        " --batch_size 64 \\\n",
        " --cutoff_date 2024-10-01"
      ],
      "metadata": {
        "id": "er1uhZTICBus",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/evaluate.py \\\n",
        " --predictions output/predictions/predictions_gru.csv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KZXPQNL-CBrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Sub)Second round tuning ++ Feature Aggregation Parameters"
      ],
      "metadata": {
        "id": "QhW2MBWOhCRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.hypersearch import HyperSearch\n",
        "\n",
        "hs = HyperSearch(\n",
        "    max_runs=30000,\n",
        "    search_mode=\"full\"   # or \"quick\"\n",
        ")\n",
        "hs.run()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ffPQko31Bc7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "RUN_DIR = Path(\"/content/drive/MyDrive/CS7643 Project/OMSCS_7643_F2025_Project/output/hyper_runs\")\n",
        "\n",
        "rows = []\n",
        "\n",
        "for run_dir in sorted(RUN_DIR.iterdir()):\n",
        "    config_path = run_dir / \"config.json\"\n",
        "    result_path = run_dir / \"metrics.json\"\n",
        "\n",
        "    if not config_path.exists() or not result_path.exists():\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        config = json.load(open(config_path))\n",
        "        metrics = json.load(open(result_path))\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    pred = metrics.get(\"model_predictions\", {})\n",
        "    subsets = pred.get(\"subset_metrics\", {})\n",
        "\n",
        "    # ============ TEST METRICS  ============\n",
        "    test = subsets.get(\"test\", {})\n",
        "    test_reg = test.get(\"regression_metrics\", {})\n",
        "    test_strat = test.get(\"strategy_metrics\", {})\n",
        "\n",
        "    test_ic = test_reg.get(\"pearson_ic\", None)\n",
        "    test_sharpe = test_strat.get(\"sharpe\", None)\n",
        "\n",
        "    # ============ HOLDOUT METRICS  ============\n",
        "    hold = subsets.get(\"holdout\", {})\n",
        "    hold_reg = hold.get(\"regression_metrics\", {})\n",
        "    hold_strat = hold.get(\"strategy_metrics\", {})\n",
        "\n",
        "    hold_ic = hold_reg.get(\"pearson_ic\", None)\n",
        "    hold_sharpe = hold_strat.get(\"sharpe\", None)\n",
        "\n",
        "    rows.append({\n",
        "        \"run\": run_dir.name,\n",
        "        \"model\": config.get(\"model\"),\n",
        "        \"test_IC\": test_ic,\n",
        "        \"test_Sharpe\": test_sharpe,\n",
        "        \"holdout_IC\": hold_ic,\n",
        "        \"holdout_Sharpe\": hold_sharpe,\n",
        "        \"config\": config\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "print(\"\\n=== Run Count Per Model ===\")\n",
        "print(df[\"model\"].value_counts())\n",
        "\n",
        "# ===============================================================\n",
        "# === APPLY HYPERSEARCH LOGIC: test_Sharpe > 0 & maximize test_IC\n",
        "# ===============================================================\n",
        "df_valid = df[df[\"test_Sharpe\"] > 0]   # HyperSearch willfilter Sharpe≤0 runs\n",
        "\n",
        "print(\"\\n=== Best Run Per Model (HyperSearch Logic: test_sharpe>0 & max test_IC) ===\")\n",
        "best_runs = df_valid.sort_values(\"test_IC\", ascending=False).groupby(\"model\").head(1)\n",
        "\n",
        "print(best_runs[[\n",
        "    \"model\",\n",
        "    \"run\",\n",
        "    \"test_IC\",\n",
        "    \"test_Sharpe\",\n",
        "    \"holdout_IC\",\n",
        "    \"holdout_Sharpe\"\n",
        "]])\n",
        "\n"
      ],
      "metadata": {
        "id": "oVUhTZqhgogD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Check round 2 logs\n",
        "# import json\n",
        "# ## The original file location has been moved to output1128 folder\n",
        "# best_dir = \"/content/drive/MyDrive/CS7643 Project/OMSCS_7643_F2025_Project/output/hyper_runs_2nd_round/run_0332\"\n",
        "\n",
        "# with open(best_dir + \"/config.json\") as f:\n",
        "#     config = json.load(f)\n",
        "# config"
      ],
      "metadata": {
        "id": "J4PtWIlikJ4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproducing the best IC models"
      ],
      "metadata": {
        "id": "D5iZ6WZZsPOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##GRU\n",
        "!python scripts/build_features.py --horizon 3 --lookback 48 --lookback-mode exp_decay\n",
        "!python scripts/train.py --model gru --seq_len 12 --batch_size 128 --lr 3e-05 --epochs 15 --weight_decay 0.0 --warmup_pct 0.05 --hidden_dim 256 --lstm_proj_dim 32 --num_layers 2 --tf_d_model 512 --tf_heads 4 --tf_layers 4 --tf_ff_dim 256 --tf_pool attention --tf_dropout 0.1\n",
        "!python scripts/predict.py --model gru --seq_len 12 --batch_size 128 --cutoff_date 2024-10-01\n",
        "!python scripts/evaluate.py --include-holdout --predictions output/predictions/predictions_gru.csv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rrFqXkDbnOPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer\n",
        "!python scripts/build_features.py --horizon 3 --lookback 24 --lookback-mode attn\n",
        "!python scripts/train.py --model transformer --seq_len 8 --batch_size 128 --lr 0.0001 --epochs 30 --weight_decay 0.0 --scheduler cosine_warmup --warmup_pct 0.1 --hidden_dim 768 --lstm_proj_dim 64 --num_layers 2 --tf_d_model 384 --tf_heads 2 --tf_layers 2 --tf_ff_dim 256 --tf_pool attention --tf_dropout 0.1\n",
        "!python scripts/predict.py --model transformer --seq_len 8 --batch_size 128 --cutoff_date 2024-10-01\n",
        "!python scripts/evaluate.py --include-holdout --predictions output/predictions/predictions_transformer.csv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O-G75Uy6sMK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MLP\n",
        "!python scripts/build_features.py --horizon 3 --lookback 6 --lookback-mode volume\n",
        "!python scripts/train.py --model mlp --seq_len 1 --batch_size 64 --lr 3e-05 --epochs 15 --weight_decay 0.0001 --scheduler cosine_warmup --warmup_pct 0.05 --hidden_dim 256 --lstm_proj_dim 32 --num_layers 2 --tf_d_model 512 --tf_heads 4 --tf_layers 4 --tf_ff_dim 1024 --tf_pool cls --tf_dropout 0.1\n",
        "!python scripts/predict.py --model mlp --seq_len 1 --batch_size 64 --cutoff_date 2024-10-01\n",
        "!python scripts/evaluate.py --include-holdout --predictions output/predictions/predictions_mlp.csv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-IUg0L50wgxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LSTM\n",
        "!python scripts/build_features.py --horizon 1 --lookback 12 --lookback-mode max\n",
        "!python scripts/train.py --model lstm --seq_len 12 --batch_size 128 --lr 0.0001 --epochs 30 --weight_decay 1e-05 --warmup_pct 0.1 --hidden_dim 256 --lstm_proj_dim 256 --num_layers 2 --tf_d_model 512 --tf_heads 8 --tf_layers 2 --tf_ff_dim 512 --tf_pool cls --tf_dropout 0.1\n",
        "!python scripts/predict.py --model lstm --seq_len 12 --batch_size 128 --cutoff_date 2024-10-01\n",
        "!python scripts/evaluate.py --include-holdout --predictions output/predictions/predictions_lstm.csv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zMxeWcjAwp16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Sub)3-5 Rounds Tuning ++ More Horizon and Lookback"
      ],
      "metadata": {
        "id": "cn6iTEbNh1YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.hypersearch import HyperSearch\n",
        "\n",
        "hs = HyperSearch(\n",
        "    max_runs=30000,\n",
        "    search_mode=\"full\"   # or \"quick\"\n",
        ")\n",
        "hs.run()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gcHfeM9Eh0vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Paths\n",
        "BASE = Path(\"/content/drive/MyDrive/CS7643 Project/OMSCS_7643_F2025_Project/output/Tuning\")\n",
        "SUMMARY_PATH = BASE / \"Tuning_Summary.xlsx\"\n",
        "\n",
        "# Folder mapping based on round number\n",
        "ROUND_TO_FOLDER = {\n",
        "    3: BASE / \"hyper_runs_3rd_round\",\n",
        "    4: BASE / \"hyper_runs_4th_round\",\n",
        "    5: BASE / \"hyper_runs_5th_round\"\n",
        "}\n",
        "\n",
        "# Load summary file\n",
        "df = pd.read_excel(SUMMARY_PATH)\n",
        "\n",
        "# Prepare new columns\n",
        "df[\"IC_holdout\"] = None\n",
        "df[\"Sharpe_holdout\"] = None\n",
        "\n",
        "def load_metrics(metrics_path):\n",
        "    \"\"\"Load metrics.json safely.\"\"\"\n",
        "    try:\n",
        "        with open(metrics_path, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Process each row\n",
        "for idx, row in df.iterrows():\n",
        "    round_num = int(row[\"Round\"])\n",
        "    run_id = int(row[\"run_id\"])\n",
        "\n",
        "    # Determine run folder\n",
        "    run_folder = ROUND_TO_FOLDER[round_num] / f\"run_{run_id:04d}\"\n",
        "    metrics_path = run_folder / \"metrics.json\"\n",
        "\n",
        "    if not metrics_path.exists():\n",
        "        print(f\"[Warning] Missing metrics.json: {metrics_path}\")\n",
        "        continue\n",
        "\n",
        "    metrics = load_metrics(metrics_path)\n",
        "    if metrics is None:\n",
        "        print(f\"[Warning] Could not load metrics: {metrics_path}\")\n",
        "        continue\n",
        "\n",
        "    # Extract holdout metrics\n",
        "    subset = metrics.get(\"model_predictions\", {}).get(\"subset_metrics\", {})\n",
        "    hold = subset.get(\"holdout\", {})\n",
        "\n",
        "    hold_reg = hold.get(\"regression_metrics\", {})\n",
        "    hold_strat = hold.get(\"strategy_metrics\", {})\n",
        "\n",
        "    ic = hold_reg.get(\"pearson_ic\", None)\n",
        "    sharpe = hold_strat.get(\"sharpe\", None)\n",
        "\n",
        "    df.at[idx, \"IC_holdout\"] = ic\n",
        "    df.at[idx, \"Sharpe_holdout\"] = sharpe\n",
        "\n",
        "    print(f\"Round {round_num} run {run_id} → Holdout IC={ic}, Sharpe={sharpe}\")\n",
        "\n",
        "# Save updated file\n",
        "output_path = BASE / \"Tuning_Summary_with_holdout.xlsx\"\n",
        "df.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"\\nSaved: {output_path}\")\n"
      ],
      "metadata": {
        "id": "okxIAxJNzPPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproduce best models round 3,4,5"
      ],
      "metadata": {
        "id": "2n08le7CrDUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Best Avg SR across Test and Holdout\n",
        "# !python scripts/build_features.py --horizon 1 --lookback 12 --lookback-mode attn\n",
        "# !python scripts/train.py --model lstm --seq_len 720 --batch_size 128 --lr 0.0001 --epochs 15 --weight_decay 0.0001 --warmup_pct 0.05 --hidden_dim 768 --lstm_proj_dim 128 --num_layers 3 --tf_d_model 384 --tf_heads 2 --tf_layers 4 --tf_ff_dim 512 --tf_pool cls --tf_dropout 0.2\n",
        "# !python scripts/predict.py --model lstm --seq_len 720 --batch_size 128 --cutoff_date 2024-10-01\n",
        "# !python scripts/evaluate.py --include-holdout --predictions output/predictions/predictions_lstm.csv"
      ],
      "metadata": {
        "id": "nnN4PmkvrB9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Best Avg SR across Test and Holdout\n",
        "# !python scripts/build_features.py --horizon 1 --lookback 6 --lookback-mode mean\n",
        "# !python scripts/train.py --model gru --seq_len 12 --batch_size 128 --lr 0.001 --epochs 15 --weight_decay 1e-05 --scheduler cosine_warmup --warmup_pct 0.05 --hidden_dim 768 --lstm_proj_dim 32 --num_layers 3 --tf_d_model 384 --tf_heads 8 --tf_layers 4 --tf_ff_dim 256 --tf_pool cls --tf_dropout 0.1\n",
        "# !python scripts/predict.py --model gru --seq_len 12 --batch_size 128 --cutoff_date 2024-10-01\n",
        "# !python scripts/evaluate.py --include-holdout --predictions output/predictions/predictions_gru.csv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i-Yb_-vDuF7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second round model wise tuning - for each key paramter for the model one by one"
      ],
      "metadata": {
        "id": "mOR-uoHSpc4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/hypersearch2.py --mode modelwise --max-runs 2000"
      ],
      "metadata": {
        "id": "tIo5tKnwS1Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/model_select.py"
      ],
      "metadata": {
        "id": "KaGNOTeM0MK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVacyprS0MHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KCfjCowx0MDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41u5Xwsf0L_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9Sg8qgX0L26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back up for commit"
      ],
      "metadata": {
        "id": "wCgypGKOpoZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r project_backup.zip \"/content/drive/MyDrive/CS7643 Project/OMSCS_7643_F2025_Project\" -x \"*/__pycache__/*\""
      ],
      "metadata": {
        "id": "R8Y13IgjlEU-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"project_backup.zip\")"
      ],
      "metadata": {
        "id": "yYBgFye28kaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sv9rYsPQprak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9mLQQ5SprV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### early poc of the ppl in ipynb below"
      ],
      "metadata": {
        "collapsed": false,
        "id": "DG5_6BjtPBli"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "news_path = \"/content/drive/MyDrive/CS7643 Project/OMSCS_7643_F2025_Project/data/cryptonews.csv\"\n",
        "df = pd.read_csv(news_path)\n",
        "## Test with sample data\n",
        "# df = df[:1000]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kGUccj1UWPYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "## Text Data Preprocessing\n",
        "if 'date' not in df.columns:\n",
        "    raise ValueError(\"no 'date' column\")\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "df = df.dropna(subset=['date'])\n",
        "df['content'] = (\n",
        "    \"Subject: \" +\n",
        "    df['subject'] + \". \" +\n",
        "    df['title'].fillna('') + \". \" +\n",
        "    df['text'].fillna('')\n",
        ")\n",
        "df = df[df['content'].str.strip() != \"\"]\n",
        "df = df.reset_index(drop=True)\n",
        "print(\"Example content:\\n\", df['content'].iloc[0])"
      ],
      "metadata": {
        "id": "cER8cHEMWPYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "## Finbert embedding\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModel.from_pretrained(\"ProsusAI/finbert\").to(device)\n",
        "model.eval()\n",
        "\n",
        "def get_cls_embedding(text):\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    cls_emb = outputs.last_hidden_state[:, 0, :].squeeze(0).cpu().numpy()\n",
        "    return cls_emb\n",
        "\n",
        "emb_list = []\n",
        "\n",
        "print(\"Generating CLS embeddings with subject-aware input…\")\n",
        "for text in tqdm(df['content'], total=len(df)):\n",
        "    emb = get_cls_embedding(text)\n",
        "    emb_list.append(emb)\n",
        "\n",
        "emb_matrix = np.vstack(emb_list)   # (N, 768)\n"
      ],
      "metadata": {
        "id": "mqH5UlImWPYI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "## Hourly Text Embeddings\n",
        "emb_cols = [f\"emb_{i}\" for i in range(768)]\n",
        "emb_df = pd.DataFrame(emb_matrix, columns=emb_cols)\n",
        "df_emb = pd.concat([df[['date']].reset_index(drop=True), emb_df], axis=1)\n",
        "df_emb['date_hour'] = df_emb['date'].dt.floor('H') - pd.Timedelta(hours=1)\n",
        "hourly_emb = df_emb.groupby('date_hour')[emb_cols].mean().reset_index()\n",
        "hourly_emb.head()"
      ],
      "metadata": {
        "id": "3HEhC-etWPYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "0809qXJcWPYJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "## Price Data\n",
        "price_path = r\"/content/drive/MyDrive/CS7643 Project/OMSCS_7643_F2025_Project/data/BTC_USD_hourly.parquet\"\n",
        "price_df = pd.read_parquet(price_path)\n",
        "price_df['date_hour'] = pd.to_datetime(price_df['datetime'], errors='coerce').dt.tz_localize(None).dt.floor('H')\n",
        "price_df = price_df.drop(columns=['datetime'])\n",
        "price_df.head()"
      ],
      "metadata": {
        "id": "4JV88u0_WPYJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df = price_df.merge(hourly_emb, on='date_hour', how='inner')\n",
        "df = df.sort_values('date_hour').reset_index(drop=True)\n",
        "print(\"Merged shape:\", df.shape)"
      ],
      "metadata": {
        "id": "y9BMKa8TWPYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Predict Price**"
      ],
      "metadata": {
        "id": "ASA6eduN0Htg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['target_close'] = df['close'].shift(-1)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "eYYiTrG40CcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "price_cols = ['open', 'high', 'low', 'close']\n",
        "emb_cols = [c for c in df.columns if c.startswith(\"emb_\")]\n",
        "\n",
        "feature_dim = len(price_cols) + len(emb_cols)\n",
        "print(\"feature_dim =\", feature_dim)"
      ],
      "metadata": {
        "id": "4wj65_yQWPYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "total_len = len(df)\n",
        "train_end = int(total_len * 0.7)\n",
        "\n",
        "train_df = df.iloc[:train_end]\n",
        "test_df  = df.iloc[train_end:]\n",
        "\n",
        "sub_end = int(len(train_df) * 0.9)\n",
        "subtrain_df = train_df.iloc[:sub_end]\n",
        "val_df      = train_df.iloc[sub_end:]"
      ],
      "metadata": {
        "id": "l4mnuOsqWPYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "scaler_price = MinMaxScaler()\n",
        "scaler_price.fit(subtrain_df[price_cols])\n",
        "\n",
        "sub_price  = scaler_price.transform(subtrain_df[price_cols])\n",
        "val_price  = scaler_price.transform(val_df[price_cols])\n",
        "test_price = scaler_price.transform(test_df[price_cols])\n",
        "\n",
        "# embedding\n",
        "sub_emb  = subtrain_df[emb_cols].values * 0.01\n",
        "val_emb  = val_df[emb_cols].values * 0.01\n",
        "test_emb = test_df[emb_cols].values * 0.01\n",
        "\n",
        "# combine\n",
        "X_sub_df  = np.concatenate([sub_price,  sub_emb],  axis=1)\n",
        "X_val_df  = np.concatenate([val_price,  val_emb],  axis=1)\n",
        "X_test_df = np.concatenate([test_price, test_emb], axis=1)\n",
        "\n",
        "# y scaler\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(subtrain_df[['target_close']])\n",
        "\n",
        "y_sub  = scaler_y.transform(subtrain_df[['target_close']]).reshape(-1)\n",
        "y_val  = scaler_y.transform(val_df[['target_close']]).reshape(-1)\n",
        "y_test = scaler_y.transform(test_df[['target_close']]).reshape(-1)\n"
      ],
      "metadata": {
        "id": "6eyRNg3GWPYL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_sequences(X_block, y_block, seq_len=12):\n",
        "    X_list, y_list = [], []\n",
        "\n",
        "    for i in range(seq_len, len(X_block)):\n",
        "        X_list.append(X_block[i-seq_len:i])\n",
        "        y_list.append(y_block[i])\n",
        "\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "\n",
        "seq_len = 12\n",
        "\n",
        "X_sub,  y_sub_seq  = build_sequences(X_sub_df,  y_sub,  seq_len)\n",
        "X_val,  y_val_seq  = build_sequences(X_val_df,  y_val,  seq_len)\n",
        "X_test, y_test_seq = build_sequences(X_test_df, y_test, seq_len)\n",
        "\n",
        "print(\"Sub:\", X_sub.shape, y_sub_seq.shape)\n",
        "print(\"Val:\", X_val.shape, y_val_seq.shape)\n",
        "print(\"Test:\", X_test.shape, y_test_seq.shape)\n"
      ],
      "metadata": {
        "id": "O3IrQbSLWPYL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train_all = np.concatenate([X_sub, X_val], axis=0)\n",
        "y_train_all = np.concatenate([y_sub_seq, y_val_seq], axis=0)\n",
        "\n",
        "\n",
        "model, train_losses, val_losses = train_transformer(\n",
        "    X_train_all,\n",
        "    y_train_all,\n",
        "    batch_size=32,\n",
        "    lr=1e-4,\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "id": "efoT6lx0WPYL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ---- test prediction ----\n",
        "pred_norm = predict(model, X_test)           # (N_test,)\n",
        "pred_price = scaler_y.inverse_transform(pred_norm.reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "# ---- ground truth ----\n",
        "y_true_price = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).reshape(-1)\n"
      ],
      "metadata": {
        "id": "QvkS4UoYWPYL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tKcgmFEzWPYM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "test_timestamps = test_df['date_hour'].values\n",
        "test_seq_timestamps = test_timestamps[seq_len:]\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(test_seq_timestamps, y_true_price, label='True Price', linewidth=2)\n",
        "plt.plot(test_seq_timestamps, pred_price, label='Predicted Price', linewidth=2)\n",
        "\n",
        "plt.title(\"Predicted vs Actual Close Price (Real Timestamp)\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oe6G6vxuWPYM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "mse_norm = mean_squared_error(y_test_seq, pred_norm)\n",
        "mse_real = mean_squared_error(y_true_price, pred_price)\n",
        "\n",
        "rmse = np.sqrt(mse_real)\n",
        "mae  = np.mean(np.abs(y_true_price - pred_price))\n",
        "mape = np.mean(np.abs((y_true_price - pred_price) / y_true_price)) * 100\n",
        "acc  = 1 - mape/100   # vs paper\n",
        "\n",
        "print(\"Normalized MSE:\", mse_norm)\n",
        "print(\"Real Price MSE:\", mse_real)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MAPE(%):\", mape)\n",
        "print(\"Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "T7OnbE98WPYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict Retrurn**"
      ],
      "metadata": {
        "id": "3M1tLxVg2xoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['target_ret'] = df['close'].pct_change().shift(-1)\n",
        "df = df.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "DW8rh7UN0ZBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_len = len(df)\n",
        "train_end = int(total_len * 0.7)\n",
        "\n",
        "train_df = df.iloc[:train_end]\n",
        "test_df  = df.iloc[train_end:]\n",
        "\n",
        "sub_end = int(len(train_df) * 0.9)\n",
        "subtrain_df = train_df.iloc[:sub_end]\n",
        "val_df      = train_df.iloc[sub_end:]\n",
        "scaler_price = MinMaxScaler()\n",
        "scaler_price.fit(subtrain_df[price_cols])\n",
        "\n",
        "sub_price  = scaler_price.transform(subtrain_df[price_cols])\n",
        "val_price  = scaler_price.transform(val_df[price_cols])\n",
        "test_price = scaler_price.transform(test_df[price_cols])\n",
        "\n",
        "sub_emb  = subtrain_df[emb_cols].values * 0.01\n",
        "val_emb  = val_df[emb_cols].values * 0.01\n",
        "test_emb = test_df[emb_cols].values * 0.01\n",
        "\n",
        "X_sub_df  = np.concatenate([sub_price,  sub_emb],  axis=1)\n",
        "X_val_df  = np.concatenate([val_price,  val_emb],  axis=1)\n",
        "X_test_df = np.concatenate([test_price, test_emb], axis=1)"
      ],
      "metadata": {
        "id": "lxzxKI2A22do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_ret = StandardScaler()\n",
        "scaler_ret.fit(subtrain_df[['target_ret']])\n",
        "\n",
        "y_sub  = scaler_ret.transform(subtrain_df[['target_ret']]).reshape(-1)\n",
        "y_val  = scaler_ret.transform(val_df[['target_ret']]).reshape(-1)\n",
        "y_test = scaler_ret.transform(test_df[['target_ret']]).reshape(-1)"
      ],
      "metadata": {
        "id": "fD1iF-Hj24-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_sub,  y_sub_seq  = build_sequences(X_sub_df,  y_sub,  seq_len=12)\n",
        "X_val,  y_val_seq  = build_sequences(X_val_df,  y_val,  seq_len=12)\n",
        "X_test, y_test_seq = build_sequences(X_test_df, y_test, seq_len=12)"
      ],
      "metadata": {
        "id": "7DpGs9bA26jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_all = np.concatenate([X_sub, X_val], axis=0)\n",
        "y_train_all = np.concatenate([y_sub_seq, y_val_seq], axis=0)\n",
        "\n",
        "model, train_losses, val_losses = train_transformer(\n",
        "    X_train_all,\n",
        "    y_train_all,\n",
        "    lr=1e-4,\n",
        "    batch_size=32,\n",
        "    epochs=30\n",
        ")\n",
        "\n",
        "pred_norm = predict(model, X_test)\n",
        "pred_ret = scaler_ret.inverse_transform(pred_norm.reshape(-1,1)).reshape(-1)"
      ],
      "metadata": {
        "id": "5NMg7OgR3CoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9XbZMUn-3Nz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_true_price - pred_price\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(residuals)\n",
        "plt.title(\"Residuals Over Time\")\n",
        "plt.ylabel(\"Residual (True - Pred)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4LjArRm58-SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "print(\"Return MSE:\", mean_squared_error(y_test_seq, pred_norm))\n",
        "print(\"Return R2:\", r2_score(y_test_seq, pred_norm))"
      ],
      "metadata": {
        "id": "fKGq3L__3EPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classify Up_Down**"
      ],
      "metadata": {
        "id": "hytw9UFE5SQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['return'] = df['close'].pct_change()\n",
        "df['label'] = (df['return'] > 0).astype(int)\n",
        "df = df.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "cgXrf-v_5Qz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_len = len(df)\n",
        "train_end = int(total_len * 0.7)\n",
        "\n",
        "train_df = df.iloc[:train_end]\n",
        "test_df  = df.iloc[train_end:]\n",
        "\n",
        "sub_end = int(len(train_df) * 0.9)\n",
        "subtrain_df = train_df.iloc[:sub_end]\n",
        "val_df      = train_df.iloc[sub_end:]\n",
        "\n",
        "price_cols = ['open', 'high', 'low', 'close']\n",
        "emb_cols   = [c for c in df.columns if c.startswith(\"emb_\")]\n",
        "\n",
        "# --- price scaler ---\n",
        "scaler_price = MinMaxScaler()\n",
        "scaler_price.fit(subtrain_df[price_cols])\n",
        "\n",
        "sub_price  = scaler_price.transform(subtrain_df[price_cols])\n",
        "val_price  = scaler_price.transform(val_df[price_cols])\n",
        "test_price = scaler_price.transform(test_df[price_cols])\n",
        "\n",
        "# --- embedding (scale ×0.01) ---\n",
        "sub_emb  = subtrain_df[emb_cols].values * 0.01\n",
        "val_emb  = val_df[emb_cols].values * 0.01\n",
        "test_emb = test_df[emb_cols].values * 0.01\n",
        "\n",
        "# --- combine ---\n",
        "X_sub_df  = np.concatenate([sub_price,  sub_emb],  axis=1)\n",
        "X_val_df  = np.concatenate([val_price,  val_emb],  axis=1)\n",
        "X_test_df = np.concatenate([test_price, test_emb], axis=1)\n",
        "\n",
        "# --- labels (classification) ---\n",
        "y_sub  = subtrain_df['label'].values\n",
        "y_val  = val_df['label'].values\n",
        "y_test = test_df['label'].values"
      ],
      "metadata": {
        "id": "OFroNpaf5d9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_sequences(X_block, y_block, seq_len=12):\n",
        "    X_list, y_list = [], []\n",
        "\n",
        "    for i in range(seq_len, len(X_block)):\n",
        "        X_list.append(X_block[i-seq_len:i])\n",
        "        y_list.append(y_block[i])\n",
        "\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "seq_len = 12\n",
        "\n",
        "X_sub,  y_sub_seq  = build_sequences(X_sub_df,  y_sub,  seq_len)\n",
        "X_val,  y_val_seq  = build_sequences(X_val_df,  y_val,  seq_len)\n",
        "X_test, y_test_seq = build_sequences(X_test_df, y_test, seq_len)\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"Train:\", X_sub.shape, y_sub_seq.shape)\n",
        "print(\"Val:\",   X_val.shape, y_val_seq.shape)\n",
        "print(\"Test:\",  X_test.shape, y_test_seq.shape)"
      ],
      "metadata": {
        "id": "gdLK5_-f5oQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_classifier(\n",
        "    X_sub, y_sub_seq,\n",
        "    X_val, y_val_seq,\n",
        "    lr=1e-4,\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "id": "SVbjGdsa6gSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "model.eval()\n",
        "device = next(model.parameters()).device\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(torch.tensor(X_test, dtype=torch.float32).to(device))\n",
        "    prob = torch.sigmoid(logits).cpu().numpy()\n",
        "    pred_label = (prob > 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test_seq, pred_label)\n",
        "auc = roc_auc_score(y_test_seq, prob)\n",
        "\n",
        "print(\"Test Accuracy:\", acc)\n",
        "print(\"Test AUC:\", auc)\n"
      ],
      "metadata": {
        "id": "xQJkM1g_7MMR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}